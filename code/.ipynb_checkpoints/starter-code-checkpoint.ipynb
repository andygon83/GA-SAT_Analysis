{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1\n",
    "\n",
    "## Step 1: Open the `sat_scores.csv` file. Investigate the data, and answer the questions below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. What does the data describe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "The data recorded the average scores and participation rates for students. The events are \n",
    "grouped by state, though they currently are organized as a list of lists, with the labels in the first list. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Does the data look complete? Are there any obvious issues with the observations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "The data is complete. Upon inspection I also realized that the last list in the file holds the\n",
    "averages for the three variables of interest. The second glaring problem is that all entries \n",
    "are strings. In order to perfom computational operations, I must first change the data type to \n",
    "something more workable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Describe in words what each variable(column) is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "First, I will start with the \"States\" column. It acts as a index to the data since it is the \n",
    "only immutable series we will work with. This column is populated by state name abbreviations \n",
    "in string format.\n",
    "The second column is the rate of participation by students in each state. Though not explicitly mentioned, you get this number by dividing the number of students taking the SAT \n",
    "in that state, by the total number of students in the same state.\n",
    "The third column holds the average score for the verbal section of the test. As with the second column, I assume they arrived at this number by adding all the test scores in the state and dividing by the number of test takers in the same state.\n",
    "The final column operates the same as the aforementioned column, but using the math section of \n",
    "the SAT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Load the data into a list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('../data/sat_scores.csv') as data:\n",
    "    reader = csv.reader(data)\n",
    "    satdata = list(reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Print the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['State', 'Rate', 'Verbal', 'Math'], ['CT', '82', '509', '510'], ['NJ', '81', '499', '513'], ['MA', '79', '511', '515'], ['NY', '77', '495', '505'], ['NH', '72', '520', '516'], ['RI', '71', '501', '499'], ['PA', '71', '500', '499'], ['VT', '69', '511', '506'], ['ME', '69', '506', '500'], ['VA', '68', '510', '501'], ['DE', '67', '501', '499'], ['MD', '65', '508', '510'], ['NC', '65', '493', '499'], ['GA', '63', '491', '489'], ['IN', '60', '499', '501'], ['SC', '57', '486', '488'], ['DC', '56', '482', '474'], ['OR', '55', '526', '526'], ['FL', '54', '498', '499'], ['WA', '53', '527', '527'], ['TX', '53', '493', '499'], ['HI', '52', '485', '515'], ['AK', '51', '514', '510'], ['CA', '51', '498', '517'], ['AZ', '34', '523', '525'], ['NV', '33', '509', '515'], ['CO', '31', '539', '542'], ['OH', '26', '534', '439'], ['MT', '23', '539', '539'], ['WV', '18', '527', '512'], ['ID', '17', '543', '542'], ['TN', '13', '562', '553'], ['NM', '13', '551', '542'], ['IL', '12', '576', '589'], ['KY', '12', '550', '550'], ['WY', '11', '547', '545'], ['MI', '11', '561', '572'], ['MN', '9', '580', '589'], ['KS', '9', '577', '580'], ['AL', '9', '559', '554'], ['NE', '8', '562', '568'], ['OK', '8', '567', '561'], ['MO', '8', '577', '577'], ['LA', '7', '564', '562'], ['WI', '6', '584', '596'], ['AR', '6', '562', '550'], ['UT', '5', '575', '570'], ['IA', '5', '593', '603'], ['SD', '4', '577', '582'], ['ND', '4', '592', '599'], ['MS', '4', '566', '551'], ['All', '45', '506', '514']]\n"
     ]
    }
   ],
   "source": [
    "print satdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### 6. Extract a list of the labels from the data, and remove them from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['State', 'Rate', 'Verbal', 'Math']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['CT', '82', '509', '510'],\n",
       " ['NJ', '81', '499', '513'],\n",
       " ['MA', '79', '511', '515'],\n",
       " ['NY', '77', '495', '505'],\n",
       " ['NH', '72', '520', '516'],\n",
       " ['RI', '71', '501', '499'],\n",
       " ['PA', '71', '500', '499'],\n",
       " ['VT', '69', '511', '506'],\n",
       " ['ME', '69', '506', '500'],\n",
       " ['VA', '68', '510', '501'],\n",
       " ['DE', '67', '501', '499'],\n",
       " ['MD', '65', '508', '510'],\n",
       " ['NC', '65', '493', '499'],\n",
       " ['GA', '63', '491', '489'],\n",
       " ['IN', '60', '499', '501'],\n",
       " ['SC', '57', '486', '488'],\n",
       " ['DC', '56', '482', '474'],\n",
       " ['OR', '55', '526', '526'],\n",
       " ['FL', '54', '498', '499'],\n",
       " ['WA', '53', '527', '527'],\n",
       " ['TX', '53', '493', '499'],\n",
       " ['HI', '52', '485', '515'],\n",
       " ['AK', '51', '514', '510'],\n",
       " ['CA', '51', '498', '517'],\n",
       " ['AZ', '34', '523', '525'],\n",
       " ['NV', '33', '509', '515'],\n",
       " ['CO', '31', '539', '542'],\n",
       " ['OH', '26', '534', '439'],\n",
       " ['MT', '23', '539', '539'],\n",
       " ['WV', '18', '527', '512'],\n",
       " ['ID', '17', '543', '542'],\n",
       " ['TN', '13', '562', '553'],\n",
       " ['NM', '13', '551', '542'],\n",
       " ['IL', '12', '576', '589'],\n",
       " ['KY', '12', '550', '550'],\n",
       " ['WY', '11', '547', '545'],\n",
       " ['MI', '11', '561', '572'],\n",
       " ['MN', '9', '580', '589'],\n",
       " ['KS', '9', '577', '580'],\n",
       " ['AL', '9', '559', '554'],\n",
       " ['NE', '8', '562', '568'],\n",
       " ['OK', '8', '567', '561'],\n",
       " ['MO', '8', '577', '577'],\n",
       " ['LA', '7', '564', '562'],\n",
       " ['WI', '6', '584', '596'],\n",
       " ['AR', '6', '562', '550'],\n",
       " ['UT', '5', '575', '570'],\n",
       " ['IA', '5', '593', '603'],\n",
       " ['SD', '4', '577', '582'],\n",
       " ['ND', '4', '592', '599'],\n",
       " ['MS', '4', '566', '551'],\n",
       " ['All', '45', '506', '514']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = satdata[0]\n",
    "sat_data = satdata[1:]\n",
    "print header\n",
    "sat_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Create a list of State names extracted from the data. (Hint: use the list of labels to index on the State column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CT',\n",
       " 'NJ',\n",
       " 'MA',\n",
       " 'NY',\n",
       " 'NH',\n",
       " 'RI',\n",
       " 'PA',\n",
       " 'VT',\n",
       " 'ME',\n",
       " 'VA',\n",
       " 'DE',\n",
       " 'MD',\n",
       " 'NC',\n",
       " 'GA',\n",
       " 'IN',\n",
       " 'SC',\n",
       " 'DC',\n",
       " 'OR',\n",
       " 'FL',\n",
       " 'WA',\n",
       " 'TX',\n",
       " 'HI',\n",
       " 'AK',\n",
       " 'CA',\n",
       " 'AZ',\n",
       " 'NV',\n",
       " 'CO',\n",
       " 'OH',\n",
       " 'MT',\n",
       " 'WV',\n",
       " 'ID',\n",
       " 'TN',\n",
       " 'NM',\n",
       " 'IL',\n",
       " 'KY',\n",
       " 'WY',\n",
       " 'MI',\n",
       " 'MN',\n",
       " 'KS',\n",
       " 'AL',\n",
       " 'NE',\n",
       " 'OK',\n",
       " 'MO',\n",
       " 'LA',\n",
       " 'WI',\n",
       " 'AR',\n",
       " 'UT',\n",
       " 'IA',\n",
       " 'SD',\n",
       " 'ND',\n",
       " 'MS']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = []\n",
    "for i in sat_data[:-1]:\n",
    "    states.append(i[0])\n",
    "\n",
    "states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. Print the types of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'str'> <type 'str'> <type 'str'> <type 'str'>\n"
     ]
    }
   ],
   "source": [
    "print type(sat_data[0][0]), type(sat_data[1][0]), type(sat_data[2][0]), type(sat_data[3][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. Do any types need to be reassigned? If so, go ahead and do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[82, 509, 510], [81, 499, 513], [79, 511, 515], [77, 495, 505], [72, 520, 516], [71, 501, 499], [71, 500, 499], [69, 511, 506], [69, 506, 500], [68, 510, 501], [67, 501, 499], [65, 508, 510], [65, 493, 499], [63, 491, 489], [60, 499, 501], [57, 486, 488], [56, 482, 474], [55, 526, 526], [54, 498, 499], [53, 527, 527], [53, 493, 499], [52, 485, 515], [51, 514, 510], [51, 498, 517], [34, 523, 525], [33, 509, 515], [31, 539, 542], [26, 534, 439], [23, 539, 539], [18, 527, 512], [17, 543, 542], [13, 562, 553], [13, 551, 542], [12, 576, 589], [12, 550, 550], [11, 547, 545], [11, 561, 572], [9, 580, 589], [9, 577, 580], [9, 559, 554], [8, 562, 568], [8, 567, 561], [8, 577, 577], [7, 564, 562], [6, 584, 596], [6, 562, 550], [5, 575, 570], [5, 593, 603], [4, 577, 582], [4, 592, 599], [4, 566, 551]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "isat_data = [[int(j) for j in i[1:4]] for i in sat_data[:-1]]\n",
    "\n",
    "print isat_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. Create a dictionary for each column mapping the State to its respective value for that column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WA': 53, 'DE': 67, 'DC': 56, 'WI': 6, 'WV': 18, 'HI': 52, 'FL': 54, 'WY': 11, 'NH': 72, 'NJ': 81, 'NM': 13, 'TX': 53, 'LA': 7, 'NC': 65, 'ND': 4, 'NE': 8, 'TN': 13, 'NY': 77, 'PA': 71, 'RI': 71, 'NV': 33, 'VA': 68, 'CO': 31, 'AK': 51, 'AL': 9, 'AR': 6, 'VT': 69, 'IL': 12, 'GA': 63, 'IN': 60, 'IA': 5, 'OK': 8, 'AZ': 34, 'CA': 51, 'ID': 17, 'CT': 82, 'ME': 69, 'MD': 65, 'MA': 79, 'OH': 26, 'UT': 5, 'MO': 8, 'MN': 9, 'MI': 11, 'KS': 9, 'MT': 23, 'MS': 4, 'SC': 57, 'KY': 12, 'OR': 55, 'SD': 4}\n",
      "{'WA': 527, 'DE': 501, 'DC': 482, 'WI': 584, 'WV': 527, 'HI': 485, 'FL': 498, 'WY': 547, 'NH': 520, 'NJ': 499, 'NM': 551, 'TX': 493, 'LA': 564, 'NC': 493, 'ND': 592, 'NE': 562, 'TN': 562, 'NY': 495, 'PA': 500, 'RI': 501, 'NV': 509, 'VA': 510, 'CO': 539, 'AK': 514, 'AL': 559, 'AR': 562, 'VT': 511, 'IL': 576, 'GA': 491, 'IN': 499, 'IA': 593, 'OK': 567, 'AZ': 523, 'CA': 498, 'ID': 543, 'CT': 509, 'ME': 506, 'MD': 508, 'MA': 511, 'OH': 534, 'UT': 575, 'MO': 577, 'MN': 580, 'MI': 561, 'KS': 577, 'MT': 539, 'MS': 566, 'SC': 486, 'KY': 550, 'OR': 526, 'SD': 577}\n",
      "{'WA': 527, 'DE': 499, 'DC': 474, 'WI': 596, 'WV': 512, 'HI': 515, 'FL': 499, 'WY': 545, 'NH': 516, 'NJ': 513, 'NM': 542, 'TX': 499, 'LA': 562, 'NC': 499, 'ND': 599, 'NE': 568, 'TN': 553, 'NY': 505, 'PA': 499, 'RI': 499, 'NV': 515, 'VA': 501, 'CO': 542, 'AK': 510, 'AL': 554, 'AR': 550, 'VT': 506, 'IL': 589, 'GA': 489, 'IN': 501, 'IA': 603, 'OK': 561, 'AZ': 525, 'CA': 517, 'ID': 542, 'CT': 510, 'ME': 500, 'MD': 510, 'MA': 515, 'OH': 439, 'UT': 570, 'MO': 577, 'MN': 589, 'MI': 572, 'KS': 580, 'MT': 539, 'MS': 551, 'SC': 488, 'KY': 550, 'OR': 526, 'SD': 582}\n"
     ]
    }
   ],
   "source": [
    "rate_col = dict(zip(states, [i[0] for i in isat_data]))\n",
    "verbal_col = dict(zip(states, [i[1] for i in isat_data]))\n",
    "math_col = dict(zip(states, [i[2] for i in isat_data]))\n",
    "\n",
    "print rate_col\n",
    "print verbal_col\n",
    "print math_col\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11. Create a dictionary with the values for each of the numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'math': [510,\n",
       "  513,\n",
       "  515,\n",
       "  505,\n",
       "  516,\n",
       "  499,\n",
       "  499,\n",
       "  506,\n",
       "  500,\n",
       "  501,\n",
       "  499,\n",
       "  510,\n",
       "  499,\n",
       "  489,\n",
       "  501,\n",
       "  488,\n",
       "  474,\n",
       "  526,\n",
       "  499,\n",
       "  527,\n",
       "  499,\n",
       "  515,\n",
       "  510,\n",
       "  517,\n",
       "  525,\n",
       "  515,\n",
       "  542,\n",
       "  439,\n",
       "  539,\n",
       "  512,\n",
       "  542,\n",
       "  553,\n",
       "  542,\n",
       "  589,\n",
       "  550,\n",
       "  545,\n",
       "  572,\n",
       "  589,\n",
       "  580,\n",
       "  554,\n",
       "  568,\n",
       "  561,\n",
       "  577,\n",
       "  562,\n",
       "  596,\n",
       "  550,\n",
       "  570,\n",
       "  603,\n",
       "  582,\n",
       "  599,\n",
       "  551],\n",
       " 'rate': [82,\n",
       "  81,\n",
       "  79,\n",
       "  77,\n",
       "  72,\n",
       "  71,\n",
       "  71,\n",
       "  69,\n",
       "  69,\n",
       "  68,\n",
       "  67,\n",
       "  65,\n",
       "  65,\n",
       "  63,\n",
       "  60,\n",
       "  57,\n",
       "  56,\n",
       "  55,\n",
       "  54,\n",
       "  53,\n",
       "  53,\n",
       "  52,\n",
       "  51,\n",
       "  51,\n",
       "  34,\n",
       "  33,\n",
       "  31,\n",
       "  26,\n",
       "  23,\n",
       "  18,\n",
       "  17,\n",
       "  13,\n",
       "  13,\n",
       "  12,\n",
       "  12,\n",
       "  11,\n",
       "  11,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  7,\n",
       "  6,\n",
       "  6,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  4,\n",
       "  4],\n",
       " 'verbal': [509,\n",
       "  499,\n",
       "  511,\n",
       "  495,\n",
       "  520,\n",
       "  501,\n",
       "  500,\n",
       "  511,\n",
       "  506,\n",
       "  510,\n",
       "  501,\n",
       "  508,\n",
       "  493,\n",
       "  491,\n",
       "  499,\n",
       "  486,\n",
       "  482,\n",
       "  526,\n",
       "  498,\n",
       "  527,\n",
       "  493,\n",
       "  485,\n",
       "  514,\n",
       "  498,\n",
       "  523,\n",
       "  509,\n",
       "  539,\n",
       "  534,\n",
       "  539,\n",
       "  527,\n",
       "  543,\n",
       "  562,\n",
       "  551,\n",
       "  576,\n",
       "  550,\n",
       "  547,\n",
       "  561,\n",
       "  580,\n",
       "  577,\n",
       "  559,\n",
       "  562,\n",
       "  567,\n",
       "  577,\n",
       "  564,\n",
       "  584,\n",
       "  562,\n",
       "  575,\n",
       "  593,\n",
       "  577,\n",
       "  592,\n",
       "  566]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maindict = {'math':[], 'verbal':[], 'rate':[]}\n",
    "for i in isat_data:\n",
    "    maindict['rate'].append(i[0])\n",
    "    maindict['verbal'].append(i[1])\n",
    "    maindict['math'].append(i[2])\n",
    "    \n",
    "maindict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Describe the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 12. Print the min and max of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 13. Write a function using only list comprehensions, no loops, to compute Standard Deviation. Print the Standard Deviation of each numeric column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Visualize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### 14. Using MatPlotLib and PyPlot, plot the distribution of the Rate using histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 15. Plot the Math(s) distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 16. Plot the Verbal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 17. What is the typical assumption for data distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 18. Does that distribution hold true for our data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 19. Plot some scatterplots. **BONUS**: Use a PyPlot `figure` to present multiple plots at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 20. Are there any interesting relationships to note?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 21. Create box plots for each variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BONUS: Using Tableau, create a heat map for each variable using a map of the US. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
